{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd34dc4-3fa4-4787-b99d-3fa93702d7e4",
   "metadata": {},
   "source": [
    "# LOADING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239977c8-6d83-4243-993b-74992569bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from tensorflow.keras.layers import Input, Dense  \n",
    "from tensorflow.keras.models import Model \n",
    "from sklearn.exceptions import NotFittedError\n",
    "from tensorflow.keras import regularizers\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from scapy.all import *\n",
    "import time\n",
    "import random\n",
    "import threading\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "pd.set_option('display.max_columns',None)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c0ad684-7fb1-4090-9721-dceb8ac7fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Train and Test dataset\n",
    "data_train =pd.read_csv('KDDTrain+.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d969f67-6d5e-4af3-837c-610d2342b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot'\n",
    ",'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations'\n",
    ",'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate'\n",
    ",'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'\n",
    ",'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate'\n",
    ",'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','outcome','level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf25d2d3-a955-4d08-b3fe-d7295ac071d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign name for columns\n",
    "data_train.columns = columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a1c175-d577-4ca4-b09d-7adebbf572c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.loc[data_train['outcome'] == \"normal\", \"outcome\"] = 'normal'\n",
    "data_train.loc[data_train['outcome'] != 'normal', \"outcome\"] = 'attack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d164f385-bc5a-4c53-b53e-ca309ae64f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scaling(df_num, cols):\n",
    "    std_scaler = RobustScaler()\n",
    "    std_scaler_temp = std_scaler.fit_transform(df_num)\n",
    "    std_df = pd.DataFrame(std_scaler_temp, columns =cols)\n",
    "    return std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48562295-04e8-43bf-9330-03570c245500",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['is_host_login','protocol_type','service','flag','land', 'logged_in','is_guest_login', 'level', 'outcome']\n",
    "def preprocess(dataframe):\n",
    "    df_num = dataframe.drop(cat_cols, axis=1)\n",
    "    num_cols = df_num.columns\n",
    "    scaled_df = Scaling(df_num, num_cols)\n",
    "\n",
    "    dataframe.drop(labels=num_cols, axis=\"columns\", inplace=True)\n",
    "    dataframe[num_cols] = scaled_df[num_cols]\n",
    "\n",
    "    dataframe.loc[dataframe['outcome'] == \"normal\", \"outcome\"] = 0\n",
    "    dataframe.loc[dataframe['outcome'] != 0, \"outcome\"] = 1\n",
    "\n",
    "    dataframe = pd.get_dummies(dataframe, columns = ['protocol_type', 'service', 'flag'])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a138298-bc33-4e83-b0e3-9bd5b78073a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = preprocess(data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0d335d-5f7c-4a62-b571-2000a8647bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_list = scaled_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1e2d45-e1ad-48b9-aeeb-738e253edb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaled_train.drop(['outcome', 'level'] , axis = 1).values\n",
    "\n",
    "y = scaled_train['outcome'].values\n",
    "y_reg = scaled_train['level'].values\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca = pca.fit(x)\n",
    "x_reduced = pca.transform(x)\n",
    "\n",
    "\n",
    "y = y.astype('int')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "x_train_reduced, x_test_reduced, y_train_reduced, y_test_reduced = train_test_split(x_reduced, y, test_size=0.3, random_state=42)\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x, y_reg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e75b791-e3f1-4d25-a060-8efcd686bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernal_evals = dict()\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "def evaluate_classification(model, name, X_train, X_test, y_train, y_test):\n",
    "    train_accuracy = metrics.accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = metrics.accuracy_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    train_precision = metrics.precision_score(y_train, model.predict(X_train))\n",
    "    test_precision = metrics.precision_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    train_recall = metrics.recall_score(y_train, model.predict(X_train))\n",
    "    test_recall = metrics.recall_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    train_f1 = metrics.f1_score(y_train, model.predict(X_train))\n",
    "    test_f1 = metrics.f1_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    kernal_evals[str(name)] = [train_accuracy, test_accuracy, train_precision, test_precision, train_recall, test_recall, train_f1, test_f1]\n",
    "    \n",
    "    print(\"Training Accuracy \" + str(name) + \": {:.2f}%\".format(train_accuracy*100))\n",
    "    print(\"Test Accuracy \" + str(name) + \": {:.2f}%\".format(test_accuracy*100))\n",
    "    print(\"Training Precision \" + str(name) + \": {:.2f}%\".format(train_precision*100))\n",
    "    print(\"Test Precision \" + str(name) + \": {:.2f}%\".format(test_precision*100))\n",
    "    print(\"Training Recall \" + str(name) + \": {:.2f}%\".format(train_recall*100))\n",
    "    print(\"Test Recall \" + str(name) + \": {:.2f}%\".format(test_recall*100))\n",
    "    print(\"Training F1-Score \" + str(name) + \": {:.2f}%\".format(train_f1*100))\n",
    "    print(\"Test F1-Score \" + str(name) + \": {:.2f}%\".format(test_f1*100))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f86a09-c57c-4001-9e6d-eb69c69cc774",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1158dca7-beae-4dd9-a411-e9705d0d8562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source IP: 92.122.225.16, Destination IP: 192.168.0.105, Protocol: 6\n",
      "Source Port: 443, Destination Port: 58033, Flags: A\n",
      "Sequence Number: 736261711, Acknowledgment Number: 747180532\n",
      "Window Size: 501\n",
      "Recieved Packet Values: {'land': 0, 'logged_in': 0, 'is_host_login': 1, 'level': 0, 'duration': 1, 'src_bytes': 0, 'dst_bytes': 1, 'wrong_fragment': 1, 'urgent': 0, 'hot': 1, 'num_failed_logins': 0, 'num_compromised': 1, 'root_shell': 1, 'su_attempted': 0, 'num_root': 1, 'num_file_creations': 1, 'num_shells': 1, 'num_access_files': 1, 'num_outbound_cmds': 0, 'count': 1, 'srv_count': 0, 'serror_rate': 0, 'srv_serror_rate': 1, 'rerror_rate': 1, 'srv_rerror_rate': 1, 'same_srv_rate': 1, 'diff_srv_rate': 0, 'srv_diff_host_rate': 0, 'dst_host_count': 0, 'dst_host_srv_count': 0, 'dst_host_same_srv_rate': 1, 'dst_host_diff_srv_rate': 0, 'dst_host_same_src_port_rate': 0, 'dst_host_srv_diff_host_rate': 1, 'dst_host_serror_rate': 1, 'dst_host_srv_serror_rate': 1, 'dst_host_rerror_rate': 0, 'dst_host_srv_rerror_rate': 0, 'protocol_type_icmp': 1, 'protocol_type_tcp': 0, 'protocol_type_udp': 1, 'service_IRC': 1, 'service_X11': 1, 'service_Z39_50': 0, 'service_aol': 1, 'service_auth': 1, 'service_bgp': 0, 'service_courier': 0, 'service_csnet_ns': 0, 'service_ctf': 1, 'service_daytime': 1, 'service_discard': 0, 'service_domain': 0, 'service_domain_u': 0, 'service_echo': 0, 'service_eco_i': 0, 'service_ecr_i': 1, 'service_efs': 1, 'service_exec': 1, 'service_finger': 1, 'service_ftp': 0, 'service_ftp_data': 0, 'service_gopher': 1, 'service_harvest': 0, 'service_hostnames': 0, 'service_http': 1, 'service_http_2784': 1, 'service_http_443': 0, 'service_http_8001': 1, 'service_imap4': 1, 'service_iso_tsap': 0, 'service_klogin': 1, 'service_kshell': 0, 'service_ldap': 0, 'service_link': 0, 'service_login': 1, 'service_mtp': 1, 'service_name': 0, 'service_netbios_dgm': 0, 'service_netbios_ns': 1, 'service_netbios_ssn': 1, 'service_netstat': 1, 'service_nnsp': 0, 'service_nntp': 1, 'service_ntp_u': 0, 'service_other': 0, 'service_pm_dump': 1, 'service_pop_2': 0, 'service_pop_3': 1, 'service_printer': 0, 'service_private': 1, 'service_red_i': 0, 'service_remote_job': 1, 'service_rje': 0, 'service_shell': 1, 'service_smtp': 1, 'service_sql_net': 1, 'service_ssh': 0, 'service_sunrpc': 0, 'service_supdup': 0, 'service_systat': 1, 'service_telnet': 0, 'service_tftp_u': 0, 'service_tim_i': 1, 'service_time': 1, 'service_urh_i': 1, 'service_urp_i': 0, 'service_uucp': 1, 'service_uucp_path': 0, 'service_vmnet': 0, 'service_whois': 1, 'flag_OTH': 0, 'flag_REJ': 0, 'flag_RSTO': 0, 'flag_RSTOS0': 0, 'flag_RSTR': 0, 'flag_S0': 0, 'flag_S1': 0, 'flag_S2': 0, 'flag_S3': 1, 'flag_SF': 1, 'flag_SH': 0}\n"
     ]
    }
   ],
   "source": [
    "l = [0,1]\n",
    "extracted_values_dict = {}\n",
    "lock = threading.Lock()\n",
    "\n",
    "def extract_values(packet, column_names):\n",
    "    extracted_values = {}\n",
    "    for column in column_names:\n",
    "        if column in packet:\n",
    "            value = packet[column]\n",
    "            extracted_values[column] = value\n",
    "        else:\n",
    "            extracted_values[column] = random.choice(l)\n",
    "    return extracted_values\n",
    "\n",
    "\n",
    "def packet_callback(packet, column_names):\n",
    "    \n",
    "    if IP in packet:\n",
    "        src_ip = packet[IP].src\n",
    "        dst_ip = packet[IP].dst\n",
    "        protocol = packet[IP].proto\n",
    "\n",
    "        print(f\"Source IP: {src_ip}, Destination IP: {dst_ip}, Protocol: {protocol}\")\n",
    "\n",
    "        if TCP in packet:\n",
    "            src_port = packet[TCP].sport\n",
    "            dst_port = packet[TCP].dport\n",
    "            flags = packet[TCP].flags\n",
    "            seq_number = packet[TCP].seq\n",
    "            ack_number = packet[TCP].ack\n",
    "            window_size = packet[TCP].window\n",
    "\n",
    "            print(f\"Source Port: {src_port}, Destination Port: {dst_port}, Flags: {flags}\")\n",
    "            print(f\"Sequence Number: {seq_number}, Acknowledgment Number: {ack_number}\")\n",
    "            print(f\"Window Size: {window_size}\")\n",
    "\n",
    "        if UDP in packet:\n",
    "            src_port = packet[UDP].sport\n",
    "            dst_port = packet[UDP].dport\n",
    "            length = len(packet[UDP])\n",
    "\n",
    "            print(f\"Source Port: {src_port}, Destination Port: {dst_port}, Length: {length}\")\n",
    "\n",
    "        if ICMP in packet:\n",
    "            icmp_type = packet[ICMP].type\n",
    "            icmp_code = packet[ICMP].code\n",
    "\n",
    "            print(f\"ICMP Type: {icmp_type}, ICMP Code: {icmp_code}\")\n",
    "\n",
    "        # Extract more fields as needed\n",
    "        global extracted_values_dict\n",
    "        with lock:\n",
    "            extracted_values = extract_values(packet, column_names)\n",
    "            extracted_values_dict = extracted_values \n",
    "\n",
    "\n",
    "def capture_packets(interface, column_names):\n",
    "    sniff(iface=interface, prn=lambda pkt: packet_callback(pkt, column_names), store=0)\n",
    "\n",
    "interface = \"Wi-Fi\"  # Replace with your Wi-Fi interface\n",
    "column_names = ['land', 'logged_in', 'is_host_login', 'level', 'duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'protocol_type_icmp', 'protocol_type_tcp', 'protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH'] # Your list of column names\n",
    "\n",
    "# Start capturing packets in a separate thread\n",
    "\n",
    "packet_capture_thread = threading.Thread(target=lambda: sniff(iface=interface, prn=lambda pkt: packet_callback(pkt, column_names), count=1, store=0))\n",
    "packet_capture_thread.start()\n",
    "\n",
    "    # Add a delay to allow time for packet capturing and processing\n",
    "time.sleep(10)  # Adjust the delay time as needed\n",
    "\n",
    "    # Print the extracted values dictionary\n",
    "with lock:\n",
    "    print(f\"Recieved Packet Values: {extracted_values_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad9f5fd-39bf-41c9-a509-c3ca3e4c67bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2756/2756 [==============================] - 8s 2ms/step - loss: 3569426.0000 - val_loss: 5879294.0000\n",
      "Epoch 2/5\n",
      "2756/2756 [==============================] - 6s 2ms/step - loss: 3569428.7500 - val_loss: 5879294.0000\n",
      "Epoch 3/5\n",
      "2756/2756 [==============================] - 6s 2ms/step - loss: 3569430.0000 - val_loss: 5879294.0000\n",
      "Epoch 4/5\n",
      "2756/2756 [==============================] - 6s 2ms/step - loss: 3569426.0000 - val_loss: 5879294.0000\n",
      "Epoch 5/5\n",
      "2756/2756 [==============================] - 7s 2ms/step - loss: 3569425.5000 - val_loss: 5879294.0000\n",
      "2756/2756 [==============================] - 3s 1ms/step\n",
      "1181/1181 [==============================] - 3s 3ms/step\n",
      "Training and evaluating Logistic Regression\n",
      "Training and evaluating Decision Tree\n",
      "Training and evaluating  XGB Classifier\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Predicted Outcome: Attack\n"
     ]
    }
   ],
   "source": [
    "input_data = {'land': 1, 'logged_in': 0, 'is_host_login': 1, 'is_guest_login': 0, 'duration': 1, 'src_bytes': 0, 'dst_bytes': 0, 'wrong_fragment': 0,\n",
    "              'urgent': 0, 'hot': 1, 'num_failed_logins': 0, 'num_compromised': 0, 'root_shell': 0, 'su_attempted': 0, 'num_root': 1, 'num_file_creations': 1, \n",
    "              'num_shells': 1, 'num_access_files': 1, 'num_outbound_cmds': 0, 'count': 1, 'srv_count': 1, 'serror_rate': 0, 'srv_serror_rate': 0, 'rerror_rate': 1, \n",
    "              'srv_rerror_rate': 0, 'same_srv_rate': 1, 'diff_srv_rate': 1, 'srv_diff_host_rate': 0, 'dst_host_count': 0, 'dst_host_srv_count': 0, 'dst_host_same_srv_rate': 1, \n",
    "              'dst_host_diff_srv_rate': 0, 'dst_host_same_src_port_rate': 0, 'dst_host_srv_diff_host_rate': 0, 'dst_host_serror_rate': 0, 'dst_host_srv_serror_rate': 1, \n",
    "              'dst_host_rerror_rate': 0, 'dst_host_srv_rerror_rate': 1, 'protocol_type_icmp': 0, 'protocol_type_tcp': 1, 'protocol_type_udp': 1, 'service_IRC': 1,\n",
    "              'service_X11': 0, 'service_Z39_50': 0, 'service_aol': 1, 'service_auth': 1, 'service_bgp': 0, 'service_courier': 1, 'service_csnet_ns': 0, 'service_ctf': 0, \n",
    "              'service_daytime': 1, 'service_discard': 1, 'service_domain': 0, 'service_domain_u': 1, 'service_echo': 1, 'service_eco_i': 0, 'service_ecr_i': 0, \n",
    "              'service_efs': 1, 'service_exec': 1, 'service_finger': 1, 'service_ftp': 1, 'service_ftp_data': 0, 'service_gopher': 1, 'service_harvest': 0, 'service_hostnames': 1, \n",
    "              'service_http': 1, 'service_http_2784': 1, 'service_http_443': 0, 'service_http_8001': 1, 'service_imap4': 0, 'service_iso_tsap': 1, 'service_klogin': 1, \n",
    "              'service_kshell': 0, 'service_ldap': 0, 'service_link': 1, 'service_login': 0, 'service_mtp': 1, 'service_name': 1, 'service_netbios_dgm': 1, 'service_netbios_ns': 1,\n",
    "              'service_netbios_ssn': 1, 'service_netstat': 1, 'service_nnsp': 1, 'service_nntp': 1, 'service_ntp_u': 0, 'service_other': 1, 'service_pm_dump': 1, \n",
    "              'service_pop_2': 0, 'service_pop_3': 1, 'service_printer': 0, 'service_private': 0, 'service_red_i': 1, 'service_remote_job': 1, 'service_rje': 1, \n",
    "              'service_shell': 1, 'service_smtp': 0, 'service_sql_net': 0, 'service_ssh': 1, 'service_sunrpc': 1, 'service_supdup': 0, 'service_systat': 0, 'service_telnet': 1, \n",
    "              'service_tftp_u': 1, 'service_tim_i': 1, 'service_time': 0, 'service_urh_i': 0, 'service_urp_i': 1, 'service_uucp': 0, 'service_uucp_path': 1, 'service_vmnet': 1, \n",
    "              'service_whois': 0, 'flag_OTH': 1, \n",
    "              'flag_REJ': 1, 'flag_RSTO': 0, 'flag_RSTOS0': 1, 'flag_RSTR': 0, 'flag_S0': 1, 'flag_S1': 1, 'flag_S2': 0, 'flag_S3': 1, 'flag_SF': 0, 'flag_SH': 1}\n",
    "\n",
    "    # Convert the values of the dictionary in the specified order\n",
    "input_list2 = []\n",
    "for value in extracted_values_dict.values():\n",
    "    input_list2.append(value)\n",
    "input_list2 = np.array(input_list2)\n",
    "\n",
    "\n",
    "# Autoencoder model\n",
    "input_dim = x_train.shape[1]\n",
    "encoding_dim = 15\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\")(encoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "autoencoder.fit(x_train, x_train, epochs=5, batch_size=32, shuffle=True, validation_data=(x_test, x_test))\n",
    "\n",
    "# Create separate encoder model\n",
    "encoder_model = Model(inputs=input_layer, outputs=encoder)\n",
    "\n",
    "# Encode data using the trained encoder\n",
    "encoded_x_train = encoder_model.predict(x_train)\n",
    "encoded_x_test = encoder_model.predict(x_test)\n",
    "\n",
    "# Train and evaluate classifiers using encoded data\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    ' XGB Classifier': xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, random_state=50),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training and evaluating {model_name}\")\n",
    "    model.fit(encoded_x_train, y_train)\n",
    "    \n",
    "\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', n_estimators=500, random_state=50)\n",
    "xgb_classifier.fit(encoded_x_train, y_train)\n",
    "\n",
    "# Now, let's use the trained autoencoder to predict whether an input is normal or attack\n",
    "input_example = input_list2  # You can replace this with any input you want to test\n",
    "encoded_input = encoder_model.predict(np.array([input_example]))  # Encode the input\n",
    "\n",
    "# Predict the outcome using the trained classifier\n",
    "predicted_outcome = xgb_classifier.predict(encoded_input)\n",
    "\n",
    "if predicted_outcome[0] == 0:\n",
    "    print(\"Predicted Outcome: Normal\")\n",
    "else:\n",
    "    print(\"Predicted Outcome: Attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87810b0a-1472-46af-9386-ad6b2130fe59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
